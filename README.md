ğŸš€ RAG Chatbot (Open Source, CPU-Friendly)

This project implements a Retrieval-Augmented Generation (RAG) chatbot, allowing you to upload documents, generate embeddings, and query them using a local LLM.

ğŸ”§ Tech Stack

Streamlit â†’ Interactive UI for chatting and document upload

ChromaDB â†’ Vector database to store and retrieve document embeddings

HuggingFace Embeddings â†’ BAAI/bge-small-en-v1.5 for high-quality text embeddings

FAISS (alternative to ChromaDB, optional) â†’ Fast similarity search and retrieval

Phi-2 GGUF (via llama.cpp) â†’ Lightweight, local LLM for answering queries

PyPDF2 & Text loaders â†’ For PDF and TXT document ingestion and preprocessing

ğŸ“‚ Features

Upload PDFs or text files

Automatic document ingestion and chunking

Generate embeddings using HuggingFace models

Store embeddings in ChromaDB / FAISS

Query the documents using a local Phi-2 model (no API needed)

CPU-friendly setup (runs locally without GPU)


Generation Pipeline and Retrival

Ask questions and get accurate answers from uploaded documents

Perform document retrieval using embeddings stored in ChromaDB / FAISS

Generate embeddings with Hugging Face models (no API keys required)

Use a local Phi-2 language model for answering queries without internet

Retrieve relevant document chunks to build contextual answers

CPU-friendly setup â€“ runs entirely on local hardware without GPU

Interactive Streamlit interface for easy querying and exploration


Created with â¤ï¸ by Jayadeepa V\
âœ‰ï¸deepa1283023@gmail.com\
Happy Coding!âœŒï¸
